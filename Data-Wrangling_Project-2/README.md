# 📊 Project 2: Data Preprocessing & Exploratory Analysis

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Used-important?logo=pandas&logoColor=white&color=150458)](https://pandas.pydata.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--Learn-Used-orange?logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/debasisbaidya)
[![Gmail](https://img.shields.io/badge/Gmail-Mail_Me-red?logo=gmail&logoColor=white)](mailto:speak2debasis@gmail.com)
[![WhatsApp](https://img.shields.io/badge/WhatsApp-Chat-green?logo=whatsapp&logoColor=white)](https://api.whatsapp.com/send?phone=918013316086&text=Hi%20Debasis!)

---

## 🧭 Step-by-Step Process

---

### 🔹 Step 1: Importing of Libraries

Began by importing the necessary Python libraries:

- 🐼 **Pandas** for data manipulation  
- 🔢 **NumPy** for numerical operations  
- 📈 **Matplotlib** and **Seaborn** for data visualization  
- 🧪 **Scikit-learn** for machine learning preprocessing tools

---

### 🔹 Step 2: Loading of Datasets

Loaded the datasets from CSV files using Pandas. Previewed the data by displaying:

- The first few rows (`.head()`)  
- The last few rows (`.tail()`)  
- The shape, column names, data types, and `.describe()` summary

---

### 🔹 Step 3: Analyzing Datasets

Examined the structure of each dataset:

- Checked for null values and unique value counts  
- Computed basic descriptive statistics: mean, median, mode for numerical columns

---

### 🔹 Step 4: Handling Missing Values

Utilized **Scikit-learn's `SimpleImputer`** to fill in missing values:

- For **numerical columns** → used the **mean**  
- For **categorical columns** → used the **mode**

---

### 🔹 Step 5: Data Type Identification

Determined and set appropriate data types for each column  
to ensure proper downstream analysis and transformation.

---

### 🔹 Step 6: Dropping Unwanted Columns

Removed any unnecessary columns that do not contribute to the analysis,  
keeping the dataset focused and efficient.

---

### 🔹 Step 7: Merging of Datasets

Combined the cleaned datasets into a single **merged dataset**.  
Ensured correct alignment based on shared features or key variables.

---

### 🔹 Step 8: Skewness and Outlier Analysis

- Assessed the **skewness** of numerical columns to understand data distribution  
- Identified and handled **outliers** using the **Interquartile Range (IQR)** method

---

### 🔹 Step 9: Correlation Visualization

Generated a **correlation matrix** to visualize relationships  
between different variables in the final dataset.

---

## ✅ Conclusion

This step-by-step guide provides an overview of the **data preprocessing** and **exploratory analysis** conducted in this project.  
It ensures that the dataset is clean, structured, and ready for downstream machine learning or analytical tasks.

---

## 👤 About Me

**Debasis Baidya**  
Senior MIS | Data Science Intern  
✅ Automated 80%+ of manual processes at my workplace  
📊 Skilled in Python, Power BI, SQL, Google Apps Script, ML, DL, NLP  
<p align="left">
  📫 <strong>Connect with me:</strong>&nbsp;

  <a href="https://www.linkedin.com/in/debasisbaidya">
    <img src="https://img.shields.io/badge/LinkedIn-View_Profile-blue?logo=linkedin&logoColor=white" />
  </a>

  <a href="mailto:speak2debasis@gmail.com">
    <img src="https://img.shields.io/badge/Gmail-Mail_Me-red?logo=gmail&logoColor=white" />
  </a>

  <a href="https://api.whatsapp.com/send?phone=918013316086&text=Hi%20Debasis!">
    <img src="https://img.shields.io/badge/WhatsApp-Message-green?logo=whatsapp&logoColor=white" />
  </a>
</p>


---

> ⭐ If you found this project helpful or insightful, feel free to give it a ⭐ star and connect with me!
